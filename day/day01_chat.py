import os
from google import genai
from dotenv import load_dotenv

load_dotenv()

class ProjectAssistant:
    def __init__(self, system_instruction):
        self.client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))
        self.model_id = "gemini-2.0-flash-exp"
        self.system_instruction = system_instruction
        # 1. æˆ‘ä»¬æ‰‹åŠ¨ç®¡ç†å†å²è®°å½•ï¼Œä¸ä¾èµ– SDK å†…éƒ¨å±æ€§
        self.history = [] 

    def ask(self, message):
        # 2. æ„é€ å¯¹è¯
        # æˆ‘ä»¬ç›´æ¥ä½¿ç”¨ client.models.generate_contentï¼Œæ‰‹åŠ¨ä¼ é€’ history
        # è¿™æ˜¯æœ€ç¬¦åˆâ€œæ— çŠ¶æ€â€è½¬æ¢â€œæœ‰çŠ¶æ€â€çš„é€»è¾‘
        
        # ç»„è£…å½“å‰çš„è¯·æ±‚å†…å®¹ï¼šå†å²è®°å½• + å½“å‰é—®é¢˜
        messages = self.history + [{"role": "user", "parts": [{"text": message}]}]
        
        response = self.client.models.generate_content(
            model=self.model_id,
            contents=messages,
            config={'system_instruction': self.system_instruction}
        )
        
        # 3. æ›´æ–°å†å²è®°å½• (ä¿å­˜è¿™ä¸€è½®çš„ä¸€é—®ä¸€ç­”)
        self.history.append({"role": "user", "parts": [{"text": message}]})
        self.history.append({"role": "model", "parts": [{"text": response.text}]})
        
        return response.text

def main():
    instruction = "ä½ æ˜¯ä¸€ä¸ªæ¶æ„å¸ˆï¼Œè¯´è¯ç®€æ´ã€‚ä½ ç°åœ¨çš„ä»»åŠ¡æ˜¯ååŠ©ä¸€æ¸…å¼€å‘ä¸€ä¸ª AI é¡¹ç›®ã€‚"
    assistant = ProjectAssistant(instruction)

    print("ğŸš€ ç¨³å¥ç‰ˆåŠ©æ‰‹å·²å°±ç»ªï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼‰")
    
    while True:
        user_input = input("ä¸€æ¸… > ")
        if user_input.lower() in ['quit', 'exit']:
            break
        
        try:
            answer = assistant.ask(user_input)
            print(f"\nğŸ¤– Gemini > {answer}\n")
            print(f"ğŸ“Š å½“å‰å¯¹è¯è½®æ•°: {len(assistant.history) // 2}")
        except Exception as e:
            print(f"âŒ å‡ºé”™å•¦: {e}")

if __name__ == "__main__":
    main()